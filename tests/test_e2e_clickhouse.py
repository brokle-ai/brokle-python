#!/usr/bin/env python3
"""
End-to-End Test: SDK ‚Üí Backend ‚Üí ClickHouse
===========================================

This test validates the entire OTLP 1.38+ migration data flow:
- Python SDK sends OTLP telemetry
- Backend converts and stores to ClickHouse
- New schema: 5 materialized columns + Maps (usage_details, cost_details, pricing_snapshot, total_cost)
- Events and links arrays work
- Cost precision is maintained (Decimal 18,12)
- Traces table aggregations are accurate

Requirements:
- Backend running: make dev-server
- ClickHouse running: docker-compose up clickhouse
- API key: export BROKLE_API_KEY=bk_...
- OpenAI key (optional): export OPENAI_API_KEY=sk-...

Usage:
    python tests/test_e2e_clickhouse.py
"""

import os
import sys
import time
import json
from typing import Dict, Any, Optional
from decimal import Decimal

# Add parent directory to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    import clickhouse_connect
except ImportError:
    print("‚ùå clickhouse-connect not installed")
    print("Install with: pip install clickhouse-connect")
    sys.exit(1)

try:
    from openai import OpenAI
except ImportError:
    print("‚ö†Ô∏è  OpenAI not installed (optional)")
    print("Install with: pip install openai")
    OpenAI = None

from brokle import Brokle


# ============================================================================
# Configuration
# ============================================================================

API_KEY = os.getenv("BROKLE_API_KEY", "bk_SZJvBQDr9brY80Ln1ceNtGZMoSNc175rs3gXbnLK")
BASE_URL = os.getenv("BROKLE_BASE_URL", "http://localhost:8080")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")  # Required: export OPENAI_API_KEY=sk-...

CLICKHOUSE_HOST = os.getenv("CLICKHOUSE_HOST", "localhost")
CLICKHOUSE_PORT = int(os.getenv("CLICKHOUSE_PORT", "8123"))  # HTTP port for clickhouse-connect
CLICKHOUSE_USER = os.getenv("CLICKHOUSE_USER", "brokle")
CLICKHOUSE_PASSWORD = os.getenv("CLICKHOUSE_PASSWORD", "brokle_password")
CLICKHOUSE_DATABASE = os.getenv("CLICKHOUSE_DATABASE", "default")


# ============================================================================
# Utilities
# ============================================================================

def print_banner(text: str, char: str = "=") -> None:
    """Print a banner with the given text."""
    width = max(70, len(text) + 4)
    print(f"\n{char * width}")
    print(f"{text:^{width}}")
    print(f"{char * width}\n")


def print_section(text: str) -> None:
    """Print a section header."""
    print(f"\n{'‚îÄ' * 60}")
    print(f"üß™ {text}")
    print('‚îÄ' * 60)


def print_success(text: str) -> None:
    """Print success message."""
    print(f"‚úÖ {text}")


def print_error(text: str) -> None:
    """Print error message."""
    print(f"‚ùå {text}")


def print_warning(text: str) -> None:
    """Print warning message."""
    print(f"‚ö†Ô∏è  {text}")


def print_info(text: str) -> None:
    """Print info message."""
    print(f"‚ÑπÔ∏è  {text}")


# ============================================================================
# ClickHouse Connection
# ============================================================================

def get_clickhouse_client():
    """Get ClickHouse client connection."""
    try:
        client = clickhouse_connect.get_client(
            host=CLICKHOUSE_HOST,
            port=CLICKHOUSE_PORT,
            username=CLICKHOUSE_USER,
            password=CLICKHOUSE_PASSWORD,
            database=CLICKHOUSE_DATABASE,
        )
        return client
    except Exception as e:
        print_error(f"Failed to connect to ClickHouse: {e}")
        print("Make sure ClickHouse is running:")
        print("  docker-compose up clickhouse")
        sys.exit(1)


# ============================================================================
# Test 1: Simple Span with Attributes
# ============================================================================

def test_simple_span_with_attributes(brokle: Brokle, ch_client) -> bool:
    """Test 1: Simple span with custom attributes."""
    print_section("Test 1: Simple Span with Attributes")

    try:
        # Create span with attributes
        with brokle.start_as_current_span(
            name="test-simple-span",
            as_type="span",
            input="test input data",
            metadata={"test_key": "test_value", "number": 42},
            session_id="test-session-1",
            user_id="test-user-1",
            tags=["e2e-test", "simple-span"],
        ) as span:
            span.update(output="test output data")
            span_id = span.span_id
            trace_id = span.trace_id

        # Flush telemetry
        print("Flushing telemetry...")
        brokle.flush()

        # Wait for backend processing
        time.sleep(3)

        # Query ClickHouse
        print(f"Querying ClickHouse for span_id: {span_id}")
        query = """
            SELECT
                span_id,
                trace_id,
                span_name,
                span_kind,
                status_code,
                input,
                output,
                attributes,
                metadata,
                span_type
            FROM spans
            WHERE span_id = %(span_id)s
        """
        result = ch_client.query(query, parameters={"span_id": span_id})

        if result.row_count == 0:
            print_error("Span not found in ClickHouse")
            return False

        row = result.first_row
        print_success("Span found in ClickHouse")

        # Validate fields
        assert row[0] == span_id, "span_id mismatch"
        assert row[1] == trace_id, "trace_id mismatch"
        assert row[2] == "test-simple-span", "span_name mismatch"
        assert row[4] == 1, f"status_code should be 1 (OK), got {row[4]}"
        assert row[5] == "test input data", "input mismatch"
        assert row[6] == "test output data", "output mismatch"

        # Validate attributes
        span_attrs = json.loads(row[7])
        assert span_attrs.get("test_key") == "test_value", "Custom attribute missing"
        assert span_attrs.get("number") == 42, "Number attribute mismatch"

        # Validate brokle_span_type materialized column
        assert row[9] == "span", f"brokle_span_type should be 'span', got {row[9]}"

        print_success("All validations passed")
        return True

    except Exception as e:
        print_error(f"Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


# ============================================================================
# Test 2: Generation Span with Gen AI Attributes + Costs
# ============================================================================

def test_generation_span_with_genai_attributes(brokle: Brokle, ch_client) -> bool:
    """Test 2: Generation span with full Gen AI attributes and cost calculation."""
    print_section("Test 2: Generation Span with Gen AI + Costs")

    try:
        # Create generation span with Gen AI attributes
        with brokle.start_as_current_generation(
            name="test-generation",
            model="gpt-4-turbo",
            input="What is AI?",
            model_parameters={"temperature": 0.7, "max_tokens": 100},
        ) as generation:
            generation.update(
                output="AI is artificial intelligence...",
                usage={
                    "input_tokens": 50,
                    "output_tokens": 20,
                },
            )
            span_id = generation.span_id
            trace_id = generation.trace_id

        # Flush telemetry
        print("Flushing telemetry...")
        brokle.flush()

        # Wait for backend processing (cost calculation)
        time.sleep(3)

        # Query ClickHouse (new schema - 5 materialized columns + Maps)
        print(f"Querying ClickHouse for span_id: {span_id}")
        query = """
            SELECT
                span_id,
                trace_id,
                span_name,
                input,
                output,
                attributes,
                -- Materialized columns (new schema)
                model_name,
                provider_name,
                span_type,
                version,
                level,
                -- Usage & Cost Maps
                usage_details,
                cost_details,
                pricing_snapshot,
                total_cost
            FROM spans
            WHERE span_id = %(span_id)s
        """
        result = ch_client.query(query, parameters={"span_id": span_id})

        if result.row_count == 0:
            print_error("Span not found in ClickHouse")
            return False

        row = result.first_row
        print_success("Span found in ClickHouse")

        # Validate basic fields
        assert row[0] == span_id, "span_id mismatch"
        assert row[1] == trace_id, "trace_id mismatch"
        assert row[2] == "test-generation", "span_name mismatch"
        assert row[3] == "What is AI?", "input mismatch"
        assert row[4] == "AI is artificial intelligence...", "output mismatch"

        # Validate new schema materialized columns (5 columns)
        print("\nüìä Materialized Columns (New Schema):")
        print(f"  model_name: {row[6]}")
        print(f"  provider_name: {row[7]}")
        print(f"  span_type: {row[8]}")
        print(f"  version: {row[9]}")
        print(f"  level: {row[10]}")

        assert row[6] == "gpt-4-turbo", f"model_name should be 'gpt-4-turbo', got {row[6]}"
        assert row[8] == "generation", f"span_type should be 'generation', got {row[8]}"

        # Validate usage & cost Maps (new schema)
        usage_details = row[11]
        cost_details = row[12]
        pricing_snapshot = row[13]
        total_cost = row[14]

        print("\nüí∞ Usage & Cost Maps (New Schema):")
        print(f"  usage_details: {usage_details}")
        print(f"  cost_details: {cost_details}")
        print(f"  pricing_snapshot: {pricing_snapshot}")
        print(f"  total_cost: {total_cost}")

        # Validate usage Map
        if usage_details:
            assert usage_details.get("input") == 50 or usage_details.get("prompt") == 50, \
                f"input_tokens should be 50, got {usage_details}"
            assert usage_details.get("output") == 20 or usage_details.get("completion") == 20, \
                f"output_tokens should be 20, got {usage_details}"
            print_success(f"Usage tracked in Map: {usage_details}")
        else:
            print_warning("usage_details Map is empty")

        # Validate cost precision (should be Decimal, not None)
        if total_cost is not None:
            print_success(f"Cost total calculated: ${total_cost}")
            assert isinstance(total_cost, Decimal), "total_cost should be Decimal"
        else:
            print_warning("Total cost is NULL (model pricing may not be configured)")

        if cost_details:
            print_success(f"Cost breakdown in Map: {cost_details}")
        else:
            print_warning("cost_details Map is empty")

        # Validate attributes JSON
        span_attrs = json.loads(row[5])
        print("\nüîç Span Attributes (JSON):")
        for key in ["gen_ai.request.model", "gen_ai.usage.input_tokens", "gen_ai.usage.output_tokens"]:
            value = span_attrs.get(key)
            print(f"  {key}: {value}")
            assert value is not None, f"Attribute '{key}' missing"

        # Check that tokens are integers (OTEL 1.38+ spec)
        assert isinstance(span_attrs["gen_ai.usage.input_tokens"], int), "input_tokens should be int"
        assert isinstance(span_attrs["gen_ai.usage.output_tokens"], int), "output_tokens should be int"

        # Costs NOT in attributes - verify clean architecture (Map storage only)
        assert "brokle.cost.input" not in span_attrs, "costs should NOT be in attributes (moved to Maps)"
        assert "brokle.cost.output" not in span_attrs, "costs should NOT be in attributes (moved to Maps)"
        assert "brokle.cost.total" not in span_attrs, "costs should NOT be in attributes (moved to Maps)"
        print_success("Cost data NOT in attributes (clean Map-based storage)")

        print_success("All Gen AI validations passed")
        return True

    except Exception as e:
        print_error(f"Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


# ============================================================================
# Test 3: Nested Spans (Parent-Child Hierarchy)
# ============================================================================

def test_nested_spans_hierarchy(brokle: Brokle, ch_client) -> bool:
    """Test 3: Nested spans with parent-child relationships."""
    print_section("Test 3: Nested Spans (Parent-Child)")

    try:
        parent_span_id = None
        child_span_id = None
        trace_id = None

        # Create parent span
        with brokle.start_as_current_span("parent-operation", as_type="span") as parent:
            parent_span_id = parent.span_id
            trace_id = parent.trace_id

            # Create nested child span
            with brokle.start_as_current_span("child-operation", as_type="tool") as child:
                child_span_id = child.span_id
                child.update(output="child result")

            parent.update(output="parent result")

        # Flush telemetry
        print("Flushing telemetry...")
        brokle.flush()

        # Wait for backend processing
        time.sleep(3)

        # Query both spans (use new schema column names)
        print(f"Querying parent span: {parent_span_id}")
        query_parent = """
            SELECT span_id, trace_id, span_name, parent_span_id, span_type
            FROM spans
            WHERE span_id = %(span_id)s
        """
        parent_result = ch_client.query(query_parent, parameters={"span_id": parent_span_id})

        print(f"Querying child span: {child_span_id}")
        child_result = ch_client.query(query_parent, parameters={"span_id": child_span_id})

        if parent_result.row_count == 0:
            print_error("Parent span not found")
            return False

        if child_result.row_count == 0:
            print_error("Child span not found")
            return False

        parent_row = parent_result.first_row
        child_row = child_result.first_row

        print_success("Both spans found in ClickHouse")

        # Validate parent
        assert parent_row[0] == parent_span_id, "Parent span_id mismatch"
        assert parent_row[1] == trace_id, "Parent trace_id mismatch"
        assert parent_row[2] == "parent-operation", "Parent span_name mismatch"
        assert parent_row[3] is None or parent_row[3] == "", "Parent should have no parent_span_id"
        assert parent_row[4] == "span", "Parent brokle_span_type mismatch"

        # Validate child
        assert child_row[0] == child_span_id, "Child span_id mismatch"
        assert child_row[1] == trace_id, "Child trace_id mismatch (should match parent)"
        assert child_row[2] == "child-operation", "Child span_name mismatch"
        assert child_row[3] == parent_span_id, f"Child parent_span_id should be {parent_span_id}, got {child_row[3]}"
        assert child_row[4] == "tool", "Child brokle_span_type mismatch"

        print_success("Parent-child hierarchy validated")
        return True

    except Exception as e:
        print_error(f"Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


# ============================================================================
# Test 4: Materialized Columns (New Schema - 5 columns)
# ============================================================================

def test_materialized_columns(brokle: Brokle, ch_client) -> bool:
    """Test 4: Validate 5 materialized columns in new schema."""
    print_section("Test 4: Materialized Columns (New Schema)")

    try:
        # Create span with attributes
        with brokle.start_as_current_span(
            name="test-materialized",
            as_type="generation",
            input="test input",
            metadata={
                "gen_ai.provider.name": "openai",
                "gen_ai.request.model": "gpt-4",
                "brokle.span.type": "generation",
                "brokle.span.level": "DEFAULT",
                "brokle.span.version": "v1",
            },
        ) as span:
            span.update(output="test output")
            span_id = span.span_id

        # Flush telemetry
        print("Flushing telemetry...")
        brokle.flush()

        # Wait for backend processing
        time.sleep(3)

        # Query ONLY the 5 materialized columns (new schema)
        print(f"Querying materialized columns for span_id: {span_id}")
        query = """
            SELECT
                model_name,      -- From attributes.gen_ai.request.model
                provider_name,   -- From attributes.gen_ai.provider.name
                span_type,       -- From attributes.brokle.span.type
                version,         -- From attributes.brokle.span.version
                level           -- From attributes.brokle.span.level
            FROM spans
            WHERE span_id = %(span_id)s
        """
        result = ch_client.query(query, parameters={"span_id": span_id})

        if result.row_count == 0:
            print_error("Span not found")
            return False

        row = result.first_row
        print_success("Span found in ClickHouse")

        # Validate 5 materialized columns
        print("\nüìã Materialized Columns Validation (New Schema):")

        materialized = {
            "model_name": (row[0], "gpt-4"),
            "provider_name": (row[1], "openai"),
            "span_type": (row[2], "generation"),
            "version": (row[3], "v1"),
            "level": (row[4], "DEFAULT"),
        }

        passed = 0
        for col_name, (actual, expected) in materialized.items():
            if actual == expected:
                print_success(f"{col_name}: {actual}")
                passed += 1
            else:
                print_error(f"{col_name}: expected {expected}, got {actual}")

        print(f"\n‚úÖ Validated {passed}/5 materialized columns")

        if passed == 5:
            print_success("All materialized columns correct (clean new schema)")
            return True
        else:
            print_error(f"Only {passed}/5 materialized columns matched")
            return False

    except Exception as e:
        print_error(f"Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


# ============================================================================
# Test 5: Events Array (OTEL 1.38+)
# ============================================================================

def test_events_array(brokle: Brokle, ch_client) -> bool:
    """Test 5: Validate OTEL events array extraction."""
    print_section("Test 5: Events Array (Streaming, Tool Calls)")

    print_warning("Events require OTEL SDK to generate - skipping for now")
    print_info("This will be tested when SDK generates span.add_event() calls")

    # TODO: Implement when SDK generates events
    # For now, check if events columns exist
    try:
        query = """
            SELECT
                events_timestamp,
                events_name,
                events_attributes
            FROM spans
            LIMIT 1
        """
        result = ch_client.query(query)
        print_success("Events columns exist in schema")
        return True
    except Exception as e:
        print_error(f"Events columns missing: {e}")
        return False


# ============================================================================
# Test 6: Links Array (OTEL 1.38+)
# ============================================================================

def test_links_array(brokle: Brokle, ch_client) -> bool:
    """Test 6: Validate OTEL links array extraction."""
    print_section("Test 6: Links Array (Distributed Tracing)")

    print_warning("Links require OTEL SDK to generate - skipping for now")
    print_info("This will be tested when SDK generates span.add_link() calls")

    # TODO: Implement when SDK generates links
    # For now, check if links columns exist
    try:
        query = """
            SELECT
                links_trace_id,
                links_span_id,
                links_attributes
            FROM spans
            LIMIT 1
        """
        result = ch_client.query(query)
        print_success("Links columns exist in schema")
        return True
    except Exception as e:
        print_error(f"Links columns missing: {e}")
        return False


# ============================================================================
# Test 7: Traces Table with Aggregations
# ============================================================================

def test_traces_table_aggregations(brokle: Brokle, ch_client) -> bool:
    """Test 7: Validate traces table and on-demand aggregations."""
    print_section("Test 7: Traces Table + Aggregations")

    try:
        # Create trace with multiple spans
        with brokle.start_as_current_span(
            name="trace-test",
            as_type="span",
            session_id="test-session-agg",
            user_id="test-user-agg",
            tags=["aggregation-test"],
        ) as parent:
            trace_id = parent.trace_id

            # Child span 1
            with brokle.start_as_current_generation(
                name="generation-1",
                model="gpt-4",
                input="prompt 1",
            ) as gen1:
                gen1.update(
                    output="output 1",
                    usage={"input_tokens": 100, "output_tokens": 50},
                )

            # Child span 2
            with brokle.start_as_current_generation(
                name="generation-2",
                model="gpt-4",
                input="prompt 2",
            ) as gen2:
                gen2.update(
                    output="output 2",
                    usage={"input_tokens": 200, "output_tokens": 100},
                )

            parent.update(output="parent complete")

        # Flush telemetry
        print("Flushing telemetry...")
        brokle.flush()

        # Wait for backend processing
        time.sleep(4)

        # Query traces table
        print(f"Querying traces table for trace_id: {trace_id}")
        query = """
            SELECT
                trace_id,
                name,
                user_id,
                session_id,
                tags,
                status_code,
                start_time,
                end_time,
                duration_ms,
                total_cost,
                total_tokens,
                span_count
            FROM traces
            WHERE trace_id = %(trace_id)s
        """
        result = ch_client.query(query, parameters={"trace_id": trace_id})

        if result.row_count == 0:
            print_error("Trace not found in traces table")
            return False

        row = result.first_row
        print_success("Trace found in traces table")

        # Validate trace-level fields
        print("\nüìä Trace Fields:")
        print(f"  trace_id: {row[0]}")
        print(f"  name: {row[1]}")
        print(f"  user_id: {row[2]}")
        print(f"  session_id: {row[3]}")
        print(f"  tags: {row[4]}")
        print(f"  status_code: {row[5]}")
        print(f"  start_time: {row[6]}")
        print(f"  end_time: {row[7]}")
        print(f"  duration_ms: {row[8]}")

        assert row[0] == trace_id, "trace_id mismatch"
        assert row[1] == "trace-test", "trace name mismatch"
        assert row[2] == "test-user-agg", "user_id mismatch"
        assert row[3] == "test-session-agg", "session_id mismatch"
        assert "aggregation-test" in row[4], "tags missing"

        # Validate aggregations (on-demand calculation)
        print("\nüí∞ Trace Aggregations:")
        print(f"  total_cost: {row[9]}")
        print(f"  total_tokens: {row[10]}")
        print(f"  span_count: {row[11]}")

        # Note: Aggregations are calculated on-demand by backend
        # They may be NULL if backend hasn't calculated them yet
        if row[11] is not None:
            print_success(f"Span count: {row[11]} (3 spans expected)")
        else:
            print_warning("Span count is NULL (on-demand not calculated yet)")

        if row[10] is not None:
            print_success(f"Total tokens: {row[10]} (450 expected: 100+50+200+100)")
        else:
            print_warning("Total tokens NULL (on-demand)")

        if row[9] is not None:
            print_success(f"Total cost: ${row[9]}")
        else:
            print_warning("Total cost NULL (on-demand)")

        # Query spans to verify count
        query_spans = """
            SELECT COUNT(*) as span_count
            FROM spans
            WHERE trace_id = %(trace_id)s
        """
        spans_result = ch_client.query(query_spans, parameters={"trace_id": trace_id})
        actual_span_count = spans_result.first_row[0]

        print(f"\nüîç Actual span count in database: {actual_span_count}")
        assert actual_span_count == 3, f"Expected 3 spans, found {actual_span_count}"

        print_success("Traces table validated")
        return True

    except Exception as e:
        print_error(f"Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


# ============================================================================
# Test 8: OpenAI Integration (Real LLM Call)
# ============================================================================

def test_openai_integration(brokle: Brokle, ch_client) -> bool:
    """Test 8: Real OpenAI call via Brokle SDK."""
    print_section("Test 8: OpenAI Integration (Real LLM)")

    if not OPENAI_API_KEY or not OpenAI:
        print_warning("OPENAI_API_KEY not set or OpenAI not installed - skipping")
        return True

    try:
        from brokle.wrappers import wrap_openai

        # Create wrapped OpenAI client
        openai_client = wrap_openai(OpenAI(api_key=OPENAI_API_KEY))

        # Make real LLM call
        print("Making real OpenAI call...")
        response = openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": "Say 'Hello from E2E test!' in exactly 5 words."}
            ],
            max_tokens=20,
            temperature=0.1,
        )

        print(f"Response: {response.choices[0].message.content}")
        print(f"Usage: {response.usage.total_tokens} tokens")

        # Flush telemetry
        print("Flushing telemetry...")
        brokle.flush()

        # Wait for backend processing
        time.sleep(4)

        # Query ClickHouse for the generation span (new schema)
        print("Querying ClickHouse for OpenAI generation...")
        query = """
            SELECT
                span_name,
                model_name,
                provider_name,
                span_type,
                usage_details,
                cost_details,
                total_cost,
                input,
                output
            FROM spans
            WHERE provider_name = 'openai'
            AND span_type = 'generation'
            ORDER BY start_time DESC
            LIMIT 1
        """
        result = ch_client.query(query)

        if result.row_count == 0:
            print_error("OpenAI generation span not found")
            return False

        row = result.first_row
        print_success("OpenAI generation found in ClickHouse")

        # Validate OpenAI-specific fields (new schema)
        print("\nü§ñ OpenAI Generation Details (New Schema):")
        print(f"  span_name: {row[0]}")
        print(f"  model_name: {row[1]}")
        print(f"  provider_name: {row[2]}")
        print(f"  span_type: {row[3]}")
        print(f"  usage_details: {row[4]}")
        print(f"  cost_details: {row[5]}")
        print(f"  total_cost: {row[6]}")

        assert row[2] == "openai", "Provider should be 'openai'"
        assert row[1] == "gpt-3.5-turbo", "Model mismatch"
        assert row[3] == "generation", "Span type should be 'generation'"

        # Validate usage Map
        usage_details = row[4]
        if usage_details:
            input_tokens = usage_details.get("input") or usage_details.get("prompt")
            output_tokens = usage_details.get("output") or usage_details.get("completion")
            print_success(f"Usage tracked: input={input_tokens}, output={output_tokens}")
            assert input_tokens is not None, "Input tokens should be populated in usage_details"
            assert output_tokens is not None, "Output tokens should be populated in usage_details"
        else:
            print_warning("usage_details Map is empty")

        # Validate cost calculation
        total_cost = row[6]
        if total_cost is not None:
            print_success(f"Cost calculated: ${total_cost}")
            assert isinstance(total_cost, Decimal), "Cost should be Decimal"
        else:
            print_warning("Cost not calculated (model pricing may not be configured)")

        print_success("OpenAI integration validated")
        return True

    except Exception as e:
        print_error(f"Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


# ============================================================================
# Main Test Runner
# ============================================================================

def main():
    """Run all E2E tests."""
    print_banner("üß™ Brokle SDK ‚Üí Backend ‚Üí ClickHouse E2E Tests", "üöÄ")

    # Initialize Brokle client
    print_section("Initializing Brokle Client")
    try:
        brokle = Brokle(
            api_key=API_KEY,
            base_url=BASE_URL,
            environment="e2e-test",
            flush_at=10,  # Small batch size for testing
            flush_interval=2.0,  # Quick flush
        )
        print_success("Brokle client initialized")
    except Exception as e:
        print_error(f"Failed to initialize Brokle client: {e}")
        sys.exit(1)

    # Initialize ClickHouse client
    print_section("Connecting to ClickHouse")
    ch_client = get_clickhouse_client()
    print_success(f"Connected to ClickHouse at {CLICKHOUSE_HOST}:{CLICKHOUSE_PORT}")

    # Run tests
    test_results = []

    with brokle:
        test_results.append(("Simple Span with Attributes", test_simple_span_with_attributes(brokle, ch_client)))
        test_results.append(("Generation Span with Gen AI + Costs", test_generation_span_with_genai_attributes(brokle, ch_client)))
        test_results.append(("Nested Spans (Parent-Child)", test_nested_spans_hierarchy(brokle, ch_client)))
        test_results.append(("Materialized Columns (5 - New Schema)", test_materialized_columns(brokle, ch_client)))
        test_results.append(("Events Array", test_events_array(brokle, ch_client)))
        test_results.append(("Links Array", test_links_array(brokle, ch_client)))
        test_results.append(("Traces Table + Aggregations", test_traces_table_aggregations(brokle, ch_client)))
        test_results.append(("OpenAI Integration", test_openai_integration(brokle, ch_client)))

    # Print summary
    print_banner("üìä Test Results Summary")

    passed = 0
    failed = 0

    for test_name, result in test_results:
        if result:
            print_success(f"{test_name}")
            passed += 1
        else:
            print_error(f"{test_name}")
            failed += 1

    print(f"\nüìä Results: {passed} passed, {failed} failed")

    if failed == 0:
        print_banner("üéâ All E2E Tests Passed! OTLP-Compliant Schema Validated!", "üéâ")
        print("‚úÖ SDK ‚Üí Backend ‚Üí ClickHouse data flow working correctly")
        print("‚úÖ New schema: 5 materialized columns + Maps (clean architecture)")
        print("‚úÖ Events and links arrays in schema")
        print("‚úÖ Cost precision maintained (Decimal 18,12)")
        print("‚úÖ Traces table aggregations working")
        print("‚úÖ Dynamic provider pricing (no stored cost attributes)")
    else:
        print_banner("‚ùå Some Tests Failed", "‚ùå")
        print("Please check the error messages above and verify:")
        print("1. Backend is running: make dev-server")
        print("2. ClickHouse is running: docker-compose up clickhouse")
        print("3. Migrations are up to date: make migrate-up")
        print("4. API key is valid")
        sys.exit(1)


if __name__ == "__main__":
    main()

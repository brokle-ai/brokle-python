# Integration Patterns Quick Reference

## ğŸ¯ Three Patterns

### Pattern 1: Drop-in Replacement (Zero Code Changes)
```python
# Instead of: from openai import OpenAI
from brokle.openai import OpenAI  # Instant observability

client = OpenAI()
response = client.chat.completions.create(...)  # Automatically tracked
```

### Pattern 2: Universal Decorator (Framework-Agnostic)
```python
from brokle import observe

@observe()
def my_ai_workflow(prompt: str):
    # Any AI call here gets tracked
    return some_llm_call(prompt)
```

### Pattern 3: Native SDK (Full Features)
```python
from brokle import Brokle

async with Brokle() as client:
    response = await client.chat.create(
        model="gpt-4",
        routing_strategy="cost_optimized",  # Smart routing
        cache_strategy="semantic"           # 30-50% cost reduction
    )
```

## ğŸ”§ Configuration

### Environment Variables
```bash
export BROKLE_API_KEY="ak_your_api_key"
export BROKLE_PROJECT_ID="proj_your_project"
export BROKLE_ENVIRONMENT="production"
```

### Programmatic Setup
```python
from brokle import Brokle, get_client

# Dedicated client
client = Brokle(api_key="ak_...", project_id="proj_...")

# Shared singleton (uses env vars)
client = get_client()
```

## ğŸš€ Pattern Benefits

### Pattern 1: Drop-in Replacement
- âœ… Zero code changes beyond import
- âœ… Works with existing OpenAI/Anthropic code
- âœ… Instant observability
- âœ… Perfect for migration

### Pattern 2: Universal Decorator
- âœ… Framework-agnostic (@observe any function)
- âœ… Works with any AI library
- âœ… Minimal code changes
- âœ… Complete workflow tracing

### Pattern 3: Native SDK
- âœ… Intelligent routing (250+ providers)
- âœ… Semantic caching (30-50% cost reduction)
- âœ… Cost optimization
- âœ… Full platform features

## ğŸ” Common Issues

### Pattern 1 (Drop-in): Import Order
```python
# âœ… Correct
from brokle.openai import OpenAI

# âŒ Wrong - use original import
from openai import OpenAI
```

### API Key Issues
```python
# Check configuration
from brokle import get_client
print(get_client().config.api_key)
```

### Pattern 3 (Native): Async Usage
```python
# âœ… Always use async context manager
async with Brokle() as client:
    response = await client.chat.create(...)
```

## ğŸ’¡ Quick Tips

- **Start with Pattern 1**: Easy migration, zero code changes
- **Upgrade to Pattern 2**: Add @observe for custom functions
- **Scale with Pattern 3**: Full platform features when needed
- **Performance**: <3ms overhead, 30-50% cost reduction
- **Compatibility**: Works with any existing AI workflow

---

*Simple. Powerful. Three patterns to fit your needs.*
